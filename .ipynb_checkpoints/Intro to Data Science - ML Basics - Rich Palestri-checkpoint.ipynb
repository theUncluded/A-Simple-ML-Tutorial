{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e129c1b",
   "metadata": {},
   "source": [
    "# This is a really nooby tutorial that will hopefully open the door for many others to learn ML. I know that there may be some great oversightings in this tutorial (and please message me if you see where improvements can be made), but the focus is to make ML as digestible as possible. Thank you for taking the time to review or look at my work - and as always - stay cool B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609fcfd",
   "metadata": {},
   "source": [
    "# What is data science? What is its interdisciplinary nature?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a488bbd",
   "metadata": {},
   "source": [
    "A field that involves the use of statistical and computational methods to extract insights from data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81700e82",
   "metadata": {},
   "source": [
    "# What are the steps of scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e854650",
   "metadata": {},
   "source": [
    "1) Import the class you plan to use\n",
    "In this step you are importing the base model for your new ML. Like the imports below, but instead of importing sklearn as a whole, we can call upon specific classes from sklearn.\n",
    "In the case of working with a classification model, using:\n",
    "```sklearn.neighbors import KNeighborsClassifier``` would be the most appropriate option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ea584bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import sklearn as sk\n",
    "import tensorflow as tf  # Tensorflow.\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3c6d1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report # Metrics\n",
    "from sklearn.model_selection import train_test_split # To split data in training/validating/testing\n",
    "from sklearn.preprocessing import StandardScaler     # To perform standardization by centering and scaling.\n",
    "from tensorflow import keras  # Keras API.\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771b8b0",
   "metadata": {},
   "source": [
    "2) Loading the data \n",
    "We start by loading the data we intend to train our model on.\n",
    "We then store the feature matrix and response vector in variables (ex. X=ds.data , y=ds.target)\n",
    "Printing the shapes of the matrices is a good sanity check :) (ex. print X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ba8f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a Pandas Dataframe with a csv, here I will use horse racing data, but you can use anything!\n",
    "df = pd.read_csv(\"data/horses_1998.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af3698c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>horseName</th>\n",
       "      <th>age</th>\n",
       "      <th>saddle</th>\n",
       "      <th>decimalPrice</th>\n",
       "      <th>isFav</th>\n",
       "      <th>trainerName</th>\n",
       "      <th>jockeyName</th>\n",
       "      <th>position</th>\n",
       "      <th>positionL</th>\n",
       "      <th>...</th>\n",
       "      <th>TR</th>\n",
       "      <th>OR</th>\n",
       "      <th>father</th>\n",
       "      <th>mother</th>\n",
       "      <th>gfather</th>\n",
       "      <th>runners</th>\n",
       "      <th>margin</th>\n",
       "      <th>weight</th>\n",
       "      <th>res_win</th>\n",
       "      <th>res_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>266487</td>\n",
       "      <td>Sadler's Realm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>Philip Hobbs</td>\n",
       "      <td>Mr R Widger</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Sadler's Wells</td>\n",
       "      <td>Rensaler</td>\n",
       "      <td>Stop The Music</td>\n",
       "      <td>7</td>\n",
       "      <td>1.431202</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266487</td>\n",
       "      <td>Handy Lass</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>Julian Smith</td>\n",
       "      <td>L Cummins</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Nicholas Bill</td>\n",
       "      <td>Mandrian</td>\n",
       "      <td>Mandamus</td>\n",
       "      <td>7</td>\n",
       "      <td>1.431202</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>266487</td>\n",
       "      <td>High Low</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "      <td>I R Jones</td>\n",
       "      <td>Miss E J Jones</td>\n",
       "      <td>3</td>\n",
       "      <td>dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Clever Trick</td>\n",
       "      <td>En Tiempo</td>\n",
       "      <td>Bold Hour</td>\n",
       "      <td>7</td>\n",
       "      <td>1.431202</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266487</td>\n",
       "      <td>Ainsi Soit Il</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>G M McCourt</td>\n",
       "      <td>Guy Lewis</td>\n",
       "      <td>4</td>\n",
       "      <td>dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Amen</td>\n",
       "      <td>Crinolene</td>\n",
       "      <td>Rheffic</td>\n",
       "      <td>7</td>\n",
       "      <td>1.431202</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>266487</td>\n",
       "      <td>D'Naan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>M C Pipe</td>\n",
       "      <td>A P McCoy</td>\n",
       "      <td>5</td>\n",
       "      <td>dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Royal Academy</td>\n",
       "      <td>Festive Season</td>\n",
       "      <td>Lypheor</td>\n",
       "      <td>7</td>\n",
       "      <td>1.431202</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rid       horseName   age  saddle  decimalPrice  isFav   trainerName  \\\n",
       "0  266487  Sadler's Realm   5.0     3.0      0.400000      1  Philip Hobbs   \n",
       "1  266487      Handy Lass   9.0     2.0      0.166667      0  Julian Smith   \n",
       "2  266487        High Low  10.0     6.0      0.153846      0     I R Jones   \n",
       "3  266487   Ainsi Soit Il   7.0     4.0      0.400000      1   G M McCourt   \n",
       "4  266487          D'Naan   5.0     7.0      0.142857      0      M C Pipe   \n",
       "\n",
       "       jockeyName  position positionL  ...  TR     OR          father  \\\n",
       "0     Mr R Widger         1       NaN  ... NaN  105.0  Sadler's Wells   \n",
       "1       L Cummins         2         5  ... NaN  111.0   Nicholas Bill   \n",
       "2  Miss E J Jones         3      dist  ... NaN   99.0    Clever Trick   \n",
       "3       Guy Lewis         4      dist  ... NaN  105.0            Amen   \n",
       "4       A P McCoy         5      dist  ... NaN   98.0   Royal Academy   \n",
       "\n",
       "           mother         gfather runners    margin  weight  res_win res_place  \n",
       "0        Rensaler  Stop The Music       7  1.431202      65      1.0         1  \n",
       "1        Mandrian        Mandamus       7  1.431202      69      0.0         1  \n",
       "2       En Tiempo       Bold Hour       7  1.431202      63      0.0         0  \n",
       "3       Crinolene         Rheffic       7  1.431202      67      0.0         0  \n",
       "4  Festive Season         Lypheor       7  1.431202      65      0.0         0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check! Let's check out the first few rows of our dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dfafd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>age</th>\n",
       "      <th>saddle</th>\n",
       "      <th>decimalPrice</th>\n",
       "      <th>isFav</th>\n",
       "      <th>position</th>\n",
       "      <th>weightSt</th>\n",
       "      <th>weightLb</th>\n",
       "      <th>overWeight</th>\n",
       "      <th>outHandicap</th>\n",
       "      <th>RPR</th>\n",
       "      <th>TR</th>\n",
       "      <th>OR</th>\n",
       "      <th>runners</th>\n",
       "      <th>margin</th>\n",
       "      <th>weight</th>\n",
       "      <th>res_win</th>\n",
       "      <th>res_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100431.000000</td>\n",
       "      <td>100430.000000</td>\n",
       "      <td>86489.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "      <td>3149.000000</td>\n",
       "      <td>4140.000000</td>\n",
       "      <td>83374.000000</td>\n",
       "      <td>54608.000000</td>\n",
       "      <td>57254.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "      <td>100431.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>222920.852157</td>\n",
       "      <td>5.092482</td>\n",
       "      <td>6.997664</td>\n",
       "      <td>0.116534</td>\n",
       "      <td>0.101771</td>\n",
       "      <td>9.407942</td>\n",
       "      <td>9.329908</td>\n",
       "      <td>6.180582</td>\n",
       "      <td>2.534138</td>\n",
       "      <td>6.968599</td>\n",
       "      <td>66.265287</td>\n",
       "      <td>56.730204</td>\n",
       "      <td>75.038792</td>\n",
       "      <td>12.810198</td>\n",
       "      <td>1.307702</td>\n",
       "      <td>61.538728</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.263514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>119987.676658</td>\n",
       "      <td>2.335003</td>\n",
       "      <td>4.779024</td>\n",
       "      <td>0.110137</td>\n",
       "      <td>0.302349</td>\n",
       "      <td>10.346820</td>\n",
       "      <td>1.276166</td>\n",
       "      <td>4.195846</td>\n",
       "      <td>2.292021</td>\n",
       "      <td>6.783789</td>\n",
       "      <td>29.364267</td>\n",
       "      <td>28.642642</td>\n",
       "      <td>23.788242</td>\n",
       "      <td>5.071201</td>\n",
       "      <td>0.172446</td>\n",
       "      <td>7.797356</td>\n",
       "      <td>0.290293</td>\n",
       "      <td>0.440541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.008734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>98602.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.185961</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>244433.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.270776</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>322804.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.386740</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>401353.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2.234097</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rid            age        saddle   decimalPrice  \\\n",
       "count  100431.000000  100430.000000  86489.000000  100431.000000   \n",
       "mean   222920.852157       5.092482      6.997664       0.116534   \n",
       "std    119987.676658       2.335003      4.779024       0.110137   \n",
       "min         0.000000      -2.000000      1.000000       0.001332   \n",
       "25%     98602.000000       3.000000      3.000000       0.047619   \n",
       "50%    244433.000000       5.000000      6.000000       0.076923   \n",
       "75%    322804.500000       7.000000     10.000000       0.142857   \n",
       "max    401353.000000      15.000000     39.000000       0.952381   \n",
       "\n",
       "               isFav       position       weightSt       weightLb  \\\n",
       "count  100431.000000  100431.000000  100431.000000  100431.000000   \n",
       "mean        0.101771       9.407942       9.329908       6.180582   \n",
       "std         0.302349      10.346820       1.276166       4.195846   \n",
       "min         0.000000       1.000000       0.000000       0.000000   \n",
       "25%         0.000000       3.000000       8.000000       2.000000   \n",
       "50%         0.000000       6.000000       9.000000       6.000000   \n",
       "75%         0.000000      11.000000      10.000000      10.000000   \n",
       "max         1.000000      40.000000      12.000000      13.000000   \n",
       "\n",
       "        overWeight  outHandicap           RPR            TR            OR  \\\n",
       "count  3149.000000  4140.000000  83374.000000  54608.000000  57254.000000   \n",
       "mean      2.534138     6.968599     66.265287     56.730204     75.038792   \n",
       "std       2.292021     6.783789     29.364267     28.642642     23.788242   \n",
       "min       1.000000     1.000000     -5.000000      1.000000      8.000000   \n",
       "25%       1.000000     2.000000     45.000000     36.000000     58.000000   \n",
       "50%       2.000000     5.000000     65.000000     55.000000     73.000000   \n",
       "75%       3.000000     9.000000     87.000000     75.000000     90.000000   \n",
       "max      38.000000   118.000000    177.000000    175.000000    175.000000   \n",
       "\n",
       "             runners         margin         weight        res_win  \\\n",
       "count  100431.000000  100431.000000  100431.000000  100431.000000   \n",
       "mean       12.810198       1.307702      61.538728       0.092900   \n",
       "std         5.071201       0.172446       7.797356       0.290293   \n",
       "min         2.000000       1.008734       0.000000       0.000000   \n",
       "25%         9.000000       1.185961      55.000000       0.000000   \n",
       "50%        12.000000       1.270776      60.000000       0.000000   \n",
       "75%        16.000000       1.386740      69.000000       0.000000   \n",
       "max        37.000000       2.234097      79.000000       1.000000   \n",
       "\n",
       "           res_place  \n",
       "count  100431.000000  \n",
       "mean        0.263514  \n",
       "std         0.440541  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's see a description of our dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55998fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rid              0.000000\n",
       "horseName        0.000000\n",
       "age              0.000996\n",
       "saddle          13.882168\n",
       "decimalPrice     0.000000\n",
       "isFav            0.000000\n",
       "trainerName      0.053768\n",
       "jockeyName       0.010953\n",
       "position         0.000000\n",
       "positionL       18.249345\n",
       "dist            27.126087\n",
       "weightSt         0.000000\n",
       "weightLb         0.000000\n",
       "overWeight      96.864514\n",
       "outHandicap     95.877767\n",
       "headGear        89.475361\n",
       "RPR             16.983800\n",
       "TR              45.626350\n",
       "OR              42.991706\n",
       "father           0.028876\n",
       "mother           0.040824\n",
       "gfather          0.310661\n",
       "runners          0.000000\n",
       "margin           0.000000\n",
       "weight           0.000000\n",
       "res_win          0.000000\n",
       "res_place        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's parse through our df to also search for null values, and for readability, let's convert it to percentage of null vals\n",
    "(df.isnull().sum() / len(df) ) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52cecf",
   "metadata": {},
   "source": [
    "# Oof, that's a lot of *dirty* data\n",
    "#### How do we fix that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9ee1e",
   "metadata": {},
   "source": [
    "- Some of these null values can definitely be forgoed. Things light headgear, OR (the official rating of the horse) , the saddle, being overweight or out on a handicap can all be disregarded for this use case\n",
    "- **BUT** there are some columns with a great amount of null values that will impact the performace of our model's training. Specifically, dist (how far a horse has finished from a first place horse), positionL (how far a horse has finished from the pursuing horse) and RPR (this is the rating of a horse's ability in relation to the weight it is carrying) are going to be necessary if we want a good prediction model.\n",
    "\n",
    "- We could take the mean values of the column and apply it to RPR, but then we would be dirtying the data more, but for the simplicity of this tutorial, let's do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9248822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's assign the mean to a variable then fill all null positions in a column with the mean\n",
    "RPRmean = df.RPR.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2c8d2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         111.000000\n",
       "1         112.000000\n",
       "2          66.265287\n",
       "3          66.265287\n",
       "4          66.265287\n",
       "             ...    \n",
       "100426     85.000000\n",
       "100427     95.000000\n",
       "100428     66.265287\n",
       "100429     66.265287\n",
       "100430     66.265287\n",
       "Name: RPR, Length: 100431, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.RPR.fillna(RPRmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dafcdf",
   "metadata": {},
   "source": [
    "## There are MANY operations to select and engineer features for your training, for the simplicity of this tutorial, we'll stick with this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00691549",
   "metadata": {},
   "source": [
    "# Now, let's define what features we want to train our model on ('X')\n",
    "## Then let's create our response vector which will pretty much be the 'goal' of our model ('Y')\n",
    "- By 'goal' I mean that's what our model will be training to do. In this case, I want the model to be able to tell me the liklihood of a horse winning a race based on 5 features I think are the most important\n",
    "- These features can realistically be whatever you want! Just mind that computers can't read super well so dummying your data into numbers may be a call you have to make. For the sake of this tutorial, I will stick to just number-based columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "116e0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's select our features now for our model and then feed them to variable X\n",
    "selected_features = [\"RPR\" , \"age\" , \"isFav\" , \"weight\"]\n",
    "# There's a problem here! Although all of these types are integer based, half are float and half are integers. This will cause a headache later so let's fix it now\n",
    "df[\"isFav\"] = pd.to_numeric(df[\"isFav\"], downcast = 'float')\n",
    "df[\"weight\"] = pd.to_numeric(df[\"weight\"], downcast = 'float')\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], downcast = 'float')\n",
    "X = df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "40fa9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store response vector in \"y\"\n",
    "y=df[\"position\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2770e4",
   "metadata": {},
   "source": [
    "# The fun begins...\n",
    "### Fitting a model with data aka training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c941611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can instantiate our train-test split on the variables above!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "51d2d7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of our Training data: (80344, 4) \n",
      "Length of our Testing data: (20087, 4)\n"
     ]
    }
   ],
   "source": [
    "#Let's print the lenghts of our training and testing data...\n",
    "print(\n",
    "    \"Length of our Training data:\",\n",
    "    X_train.shape,\n",
    "    \"\\nLength of our Testing data:\",\n",
    "    X_test.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8e374fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame(name=\"Position\")\n",
    "y_test = y_test.to_frame(name=\"Position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6158a8e",
   "metadata": {},
   "source": [
    "## Convert the pandas df's to NumPy arrays..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8da481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219bc34f",
   "metadata": {},
   "source": [
    "# Now that we're nearly there\n",
    "### Build , Train , And Evaluate our model in Tensorflow Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b85ae",
   "metadata": {},
   "source": [
    "#### Source: Georgios Ioannou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4d958",
   "metadata": {},
   "source": [
    "# What is a regressor though? What is regression?\n",
    "Regressors are able to show whether changes observed in the dependent variable are associated with changes in one \n",
    "or more of the explanatory variables.\n",
    "In english, Regression creates a line of 'best-fit' and observes and analyzes how the data fits around this point. Regressive \n",
    "models could be applied to any linearity of life. Age and height are a good example of this as they are linear by nature. \n",
    "Regressive models are commonly used as statistical proof of claims regarding everyday facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c16087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionTensorFlow(tf.keras.Model):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionTensorFlow, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(input_dim * 2, activation=\"relu\")\n",
    "        self.fc2 = tf.keras.layers.Dense(input_dim * 4, activation=\"relu\")\n",
    "        self.fc3 = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9c25703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.LogisticRegressionTensorFlow object at 0x000002C251113E10>\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the LogisticRegressionTensorFlow class model.\n",
    "\n",
    "model = LogisticRegressionTensorFlow(input_dim=X_train.shape[1])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8f062ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"logistic_regression_tensor_flow_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             multiple                  40        \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  144       \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201 (804.00 Byte)\n",
      "Trainable params: 201 (804.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Perform a forward pass with some data to initialize the model's weights by using a single example from X_train.\n",
    "\n",
    "sample_input = tf.constant(X_train[:1])\n",
    "_ = model(sample_input)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "048d3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function.\n",
    "\n",
    "criterion = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Optimizer.\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "09214c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2500], Loss: -561.6360\n",
      "Epoch [200/2500], Loss: -1738.9230\n",
      "Epoch [300/2500], Loss: -4470.2808\n",
      "Epoch [400/2500], Loss: -9948.0654\n",
      "Epoch [500/2500], Loss: -20674.9004\n",
      "Epoch [600/2500], Loss: -37617.0938\n",
      "Epoch [700/2500], Loss: -62607.2578\n",
      "Epoch [800/2500], Loss: -98785.7578\n",
      "Epoch [900/2500], Loss: -146184.9062\n",
      "Epoch [1000/2500], Loss: -205462.1406\n",
      "Epoch [1100/2500], Loss: -277307.5312\n",
      "Epoch [1200/2500], Loss: -362357.6250\n",
      "Epoch [1300/2500], Loss: -461193.6250\n",
      "Epoch [1400/2500], Loss: -574345.8125\n",
      "Epoch [1500/2500], Loss: -702299.2500\n",
      "Epoch [1600/2500], Loss: -845498.9375\n",
      "Epoch [1700/2500], Loss: -1004355.0625\n",
      "Epoch [1800/2500], Loss: -1179246.2500\n",
      "Epoch [1900/2500], Loss: -1370524.7500\n",
      "Epoch [2000/2500], Loss: -1578518.3750\n",
      "Epoch [2100/2500], Loss: -1803535.3750\n",
      "Epoch [2200/2500], Loss: -2045864.8750\n",
      "Epoch [2300/2500], Loss: -2305783.0000\n",
      "Epoch [2400/2500], Loss: -2583550.7500\n",
      "Epoch [2500/2500], Loss: -2879418.7500\n"
     ]
    }
   ],
   "source": [
    "# Training loop.\n",
    "\n",
    "num_epochs = 2500\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass.\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(y_train, outputs)\n",
    "\n",
    "    # Calculate gradients and update weights.\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "580b6442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628/628 [==============================] - 0s 449us/step\n"
     ]
    }
   ],
   "source": [
    "# Put the model in evaluation state.\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=criterion, metrics=[\"accuracy\"])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a3bc9c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score On The Test Set: 9.16%\n",
      "Precision Score On The Test Set: 9.16%\n",
      "Recall Score On The Test Set: 9.16%\n",
      "F1 Score On The Test Set: 1.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Z:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics.\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred ,average = \"weighted\", zero_division=np.nan)\n",
    "recall = recall_score(y_test, y_pred , average = \"weighted\", zero_division=np.nan)\n",
    "f1 = f1_score(y_test, y_pred , average = \"weighted\", zero_division=np.nan)\n",
    "\n",
    "print(f\"Accuracy Score On The Test Set: {accuracy:.2%}\")\n",
    "print(f\"Precision Score On The Test Set: {precision:.2%}\")\n",
    "print(f\"Recall Score On The Test Set: {recall:.2%}\")\n",
    "print(f\"F1 Score On The Test Set: {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ccafb",
   "metadata": {},
   "source": [
    "# Holy crap those scores suck!\n",
    "- This is to show the importance of picking the best data to train your model on. Although I chose only numerical data, having the model predict the horse's position based on RPR, age, isFav and weight doesn't give the model enough information. Let's mess around with the number of epochs to see if we can yield better results from a longer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1baab8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: -3193628.7500\n",
      "Epoch [200/10000], Loss: -3526413.2500\n",
      "Epoch [300/10000], Loss: -3877998.7500\n",
      "Epoch [400/10000], Loss: -4248605.0000\n",
      "Epoch [500/10000], Loss: -4638449.0000\n",
      "Epoch [600/10000], Loss: -5047744.5000\n",
      "Epoch [700/10000], Loss: -5476698.5000\n",
      "Epoch [800/10000], Loss: -5925516.5000\n",
      "Epoch [900/10000], Loss: -6394406.0000\n",
      "Epoch [1000/10000], Loss: -6883569.5000\n",
      "Epoch [1100/10000], Loss: -7393212.5000\n",
      "Epoch [1200/10000], Loss: -7923536.0000\n",
      "Epoch [1300/10000], Loss: -8474740.0000\n",
      "Epoch [1400/10000], Loss: -9047028.0000\n",
      "Epoch [1500/10000], Loss: -9640605.0000\n",
      "Epoch [1600/10000], Loss: -10255669.0000\n",
      "Epoch [1700/10000], Loss: -10892425.0000\n",
      "Epoch [1800/10000], Loss: -11551076.0000\n",
      "Epoch [1900/10000], Loss: -12231827.0000\n",
      "Epoch [2000/10000], Loss: -12934883.0000\n",
      "Epoch [2100/10000], Loss: -13660449.0000\n",
      "Epoch [2200/10000], Loss: -14408732.0000\n",
      "Epoch [2300/10000], Loss: -15179943.0000\n",
      "Epoch [2400/10000], Loss: -15974287.0000\n",
      "Epoch [2500/10000], Loss: -16791970.0000\n",
      "Epoch [2600/10000], Loss: -17633206.0000\n",
      "Epoch [2700/10000], Loss: -18498204.0000\n",
      "Epoch [2800/10000], Loss: -19387180.0000\n",
      "Epoch [2900/10000], Loss: -20300344.0000\n",
      "Epoch [3000/10000], Loss: -21237906.0000\n",
      "Epoch [3100/10000], Loss: -22200080.0000\n",
      "Epoch [3200/10000], Loss: -23187084.0000\n",
      "Epoch [3300/10000], Loss: -24199134.0000\n",
      "Epoch [3400/10000], Loss: -25236440.0000\n",
      "Epoch [3500/10000], Loss: -26299226.0000\n",
      "Epoch [3600/10000], Loss: -27387692.0000\n",
      "Epoch [3700/10000], Loss: -28502078.0000\n",
      "Epoch [3800/10000], Loss: -29642596.0000\n",
      "Epoch [3900/10000], Loss: -30809450.0000\n",
      "Epoch [4000/10000], Loss: -32002870.0000\n",
      "Epoch [4100/10000], Loss: -33223074.0000\n",
      "Epoch [4200/10000], Loss: -34470284.0000\n",
      "Epoch [4300/10000], Loss: -35744708.0000\n",
      "Epoch [4400/10000], Loss: -37046584.0000\n",
      "Epoch [4500/10000], Loss: -38376116.0000\n",
      "Epoch [4600/10000], Loss: -39733532.0000\n",
      "Epoch [4700/10000], Loss: -41119048.0000\n",
      "Epoch [4800/10000], Loss: -42532896.0000\n",
      "Epoch [4900/10000], Loss: -43975288.0000\n",
      "Epoch [5000/10000], Loss: -45446444.0000\n",
      "Epoch [5100/10000], Loss: -46946588.0000\n",
      "Epoch [5200/10000], Loss: -48475940.0000\n",
      "Epoch [5300/10000], Loss: -50034732.0000\n",
      "Epoch [5400/10000], Loss: -51623156.0000\n",
      "Epoch [5500/10000], Loss: -53241476.0000\n",
      "Epoch [5600/10000], Loss: -54889860.0000\n",
      "Epoch [5700/10000], Loss: -56568596.0000\n",
      "Epoch [5800/10000], Loss: -58277852.0000\n",
      "Epoch [5900/10000], Loss: -60017872.0000\n",
      "Epoch [6000/10000], Loss: -61788872.0000\n",
      "Epoch [6100/10000], Loss: -63591076.0000\n",
      "Epoch [6200/10000], Loss: -65424700.0000\n",
      "Epoch [6300/10000], Loss: -67289976.0000\n",
      "Epoch [6400/10000], Loss: -69187104.0000\n",
      "Epoch [6500/10000], Loss: -71116336.0000\n",
      "Epoch [6600/10000], Loss: -73077864.0000\n",
      "Epoch [6700/10000], Loss: -75071944.0000\n",
      "Epoch [6800/10000], Loss: -77098768.0000\n",
      "Epoch [6900/10000], Loss: -79158552.0000\n",
      "Epoch [7000/10000], Loss: -81251536.0000\n",
      "Epoch [7100/10000], Loss: -83377960.0000\n",
      "Epoch [7200/10000], Loss: -85537992.0000\n",
      "Epoch [7300/10000], Loss: -87731896.0000\n",
      "Epoch [7400/10000], Loss: -89959848.0000\n",
      "Epoch [7500/10000], Loss: -92222128.0000\n",
      "Epoch [7600/10000], Loss: -94518912.0000\n",
      "Epoch [7700/10000], Loss: -96850432.0000\n",
      "Epoch [7800/10000], Loss: -99216928.0000\n",
      "Epoch [7900/10000], Loss: -101618568.0000\n",
      "Epoch [8000/10000], Loss: -104055640.0000\n",
      "Epoch [8100/10000], Loss: -106528320.0000\n",
      "Epoch [8200/10000], Loss: -109036840.0000\n",
      "Epoch [8300/10000], Loss: -111581424.0000\n",
      "Epoch [8400/10000], Loss: -114162248.0000\n",
      "Epoch [8500/10000], Loss: -116779608.0000\n",
      "Epoch [8600/10000], Loss: -119433656.0000\n",
      "Epoch [8700/10000], Loss: -122124648.0000\n",
      "Epoch [8800/10000], Loss: -124852832.0000\n",
      "Epoch [8900/10000], Loss: -127618344.0000\n",
      "Epoch [9000/10000], Loss: -130421520.0000\n",
      "Epoch [9100/10000], Loss: -133262312.0000\n",
      "Epoch [9200/10000], Loss: -136141360.0000\n",
      "Epoch [9300/10000], Loss: -139058544.0000\n",
      "Epoch [9400/10000], Loss: -142014176.0000\n",
      "Epoch [9500/10000], Loss: -145008576.0000\n",
      "Epoch [9600/10000], Loss: -148041744.0000\n",
      "Epoch [9700/10000], Loss: -151114208.0000\n",
      "Epoch [9800/10000], Loss: -154225856.0000\n",
      "Epoch [9900/10000], Loss: -157377184.0000\n",
      "Epoch [10000/10000], Loss: -160568096.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop. Pt 2\n",
    "\n",
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass.\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(y_train, outputs)\n",
    "\n",
    "    # Calculate gradients and update weights.\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a73381e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628/628 [==============================] - 0s 464us/step\n"
     ]
    }
   ],
   "source": [
    "# Put the model in evaluation state.\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=criterion, metrics=[\"accuracy\"])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e97ceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score On The Test Set: 9.16%\n",
      "Precision Score On The Test Set: 9.16%\n",
      "Recall Score On The Test Set: 9.16%\n",
      "F1 Score On The Test Set: 16.78%\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics.\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred ,average = \"weighted\", zero_division=np.nan)\n",
    "recall = recall_score(y_test, y_pred , average = \"weighted\", zero_division=np.nan)\n",
    "f1 = f1_score(y_test, y_pred , average = \"weighted\", zero_division=np.nan)\n",
    "\n",
    "print(f\"Accuracy Score On The Test Set: {accuracy:.2%}\")\n",
    "print(f\"Precision Score On The Test Set: {precision:.2%}\")\n",
    "print(f\"Recall Score On The Test Set: {recall:.2%}\")\n",
    "print(f\"F1 Score On The Test Set: {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53749d03",
   "metadata": {},
   "source": [
    "# What do these scores mean?\n",
    "- Accuracy is the accuracy of the model's prediction. It achieves it's score by dividing the number of correct predictions by the total number of predictions\n",
    "##### Accuracy is a helpful metric when you deal with balanced classes and care about the overall model “correctness” and not the ability to predict a specific class. Accuracy is also easy to explain and communicate. \n",
    "\n",
    "- Precision is a metric that measures how often a machine learning model correctly predicts the positive class i.e. the correct prediction. You can calculate precision by dividing the number of correct positive predictions (true positives) by the total number of instances the model predicted as positive (both true and false positives)\n",
    "##### Precision metric works well for problems with imbalanced classes since it shows the model correctness in identifying the target class - EvidentlyAI - Precision is also useful when the cost of a false positive is high.\n",
    "\n",
    "- Recall is a metric that measures how often a machine learning model correctly identifies positive instances (true positives) from all the actual positive samples in the dataset. You can calculate recall by dividing the number of true positives by the number of positive instances\n",
    "##### Recall works well for problems with imbalanced classes since it is focused on the model’s ability to find objects of the target class i.e. 'y'.\n",
    "\n",
    "- F1 Score or F-measure for stat nerds is described as the harmonic mean of the precision and recall of a model. The two metrics contribute equally to the score, ensuring that the F1 metric correctly indicates the reliability of a model.\n",
    "##### As a general guideline, an F1 score of 0.7 or higher is often considered good. But again, you need to consider the specific context. Some applications may necessitate a higher F1 score, especially if both precision and recall are critical. - serokell.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9b1ba",
   "metadata": {},
   "source": [
    "# Thanks to those who have inspired me to dive into the world of ML and DS\n",
    "## And to the sources I have used to build this guide (See Below):\n",
    "- Zack DeSario (The man, the myth, the legend)\n",
    "- Georgios Ioannou\n",
    "- EvidentlyAI - Scoring Breakdowns\n",
    "- Serokell.io - Scoring Guidelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
